This sub-directory contains  demonstrations  of various ideas.  None
of them are implemented extremely efficiently.

They work, but they run slowly.  They are here to give you ideas and
to provide simple, somewhat readable examples,  of  various  methods
and  ideas.   Much  of  the code is *VERY* crude.  It was written as
"proof of concept" kind of thing, where I could make sure it worked,
and make some predictions about various improvements.  Also, most of
these aren't even really capable of large  pi runs (due to the way I
quickly coded them, etc.).  And many of them will have large amounts
of data on the stack.

Each  of  these  were  written  during  my  research  into  suitable
multiplication  methods  for going beyond 2g digits.  At that point,
the only things I was concerned  with was 1) it actually working, 2)
working well enough for me to be able to make some predictions as to
how it would work after optimizations, etc.  I was  _not_  concerned
with  producing  the best looking, or the fastest, or cleanest code.
Only with it actually working.

And I make *NO* guarantee's about  whether they work properly.  As I
said, they were just basic "proof of concept" type of code.


WIDEFHT
*******
This is an implementation of Knuth's  idea of a fixed point FFT.  (I
used my FHT code because it was already 'real'  and  that  made  the
testing easier.)

It  works  in  a fixed point decimal format.  The code is incredibly
crude.  And *SLOW*!  A performance improvement of about 10x could be
made fairly  easily.   (See  the  directory  for  details.)  I never
bothered to do it becaused on  estimates  (even  with  theoretically
best  implementations etc.), even after doing that, it wouldn't have
the performance I needed.  It  would  have  worked.  I just wanted /
needed faster.  It's an interesting idea, though.

WIDEFHT2
********

Same basic ideas as the widefht, except I started to hardwire it for
just 32 decimals per FHT  element.   The  idea  was to see how far I
could push the technique.  I  never really finished it.  However, by
reducing the number of digits, you can use hardwired FFT/FHT's (such
as the FHT code generated by Joerg Arndt's FXT package) and  do  the
inner  FFT  multiply  much  faster than with the generic fft used in
'widefht' above.  By  extending  the  improvements, etc., this could
almost (but not quite) be practical and useful.  (And  it  could  be
done  without  any  assembly,  unlike many of the other methods I've
done.)

Not included here, I also started to change the data format from the
int.frac format to just  a  .frac  format,  without an integer part.
That would have saved some storage.


WIDENTT
*******

This is the same basic idea  of  a software 'wide' data type, except
applied to a NTT.

Again, the code is quite slow.  The ModMul itself is done incredibly
niavely.  This could significantly improved, just like the  WideFHT.
Again,  I didn't do it because estimates showed it wouldn't have the
performance I wanted.


QUADFHT
*******

This is a FHT using a 'double-double' data type by David Bailey.  It
puts  8  decimals  into  each  fht element and can run up to several
giga-decimals.  This is in contrast  to  a  FFT that can only hold 4
decimals  up to about 8 million and then has to reduce to 3, then 2,
then even 1 decimal.  It takes 16 bytes for each  element.   At  one
million decimals, it runs about 5 times slower than a FFT.

The  code  is  a little crude.  The port from David Bailey's Fortran
code was done quickly,  with  no  real  effort  to do it clearly.  I
depended upon the compiler to deal with inefficiencies.  The FHT was
taken almost directly from the  'wide-fht'  I  had  already  tested.
That's why there are two different styles to do the wide math.

Surprisingly, this one is actually one of the _faster_ methods  I've
tested!   It's  still  slower  than  my ntt32/gcc586, but it's a lot
better than the other stuff  in  the 'demos' directory.  Its biggest
problem is that it takes too much space.  4*Digits bytes,  where  as
the ntt32 only takes 2*Digits bytes.

Be aware that I make no  guarantee that the Fortran->C conversion is
100% correct.  For the full Fortran code, see Dr. Bailey's web  page
at: http://www.nersc.gov/~dhb

(IN FACT, I STRONGLY SUSPECT THERE ARE ERRORS IN THIS CODE!)


RIGHTANG
********

This  is  a  basic  FFT  (actually taken from my Quad-2) that does a
different type  of  complex<->real  wrapper.   Where  as  the normal
method I've been using requires the data to be  ordered,  the  Right
Angle Transform (RAT) doesn't.

It  pre-processes  the  data  before  a forward transform, then post
processes the data after the  inverse transform.  That means you can
use a DiF / DiT FFT pair.  That means  no  scrambling  is  required.
That means you can make a disk based transform with a normal complex
FFT and use a RAT to do the conversion.

There's no real purpose in including this here.  I just was going to
implement  it  for doing the 'wide fft', but I changed to a wide fht
and then I started to do it  for a regular fft, but there just isn't
any real reason to do it.  I'll  probably  delete  this  before  the
final release and just mention the basics in my pi tutorial.


GALOIS
******

A fast galois transform.  Sort of  a cross between a regular FFT and
a  NTT.   Sort  of like if the two of them went behind the barn, and
nine months later the FGT was born.   This example shows how to do a
'real' FGT & convolution.  (Unlike a FFT, the FGT can  easily  do  a
'real' transform.  The main difference is how the convolution itself
is done.)  The ModMul is very niave.  Like all of the modules in the
'DEMOS'  directory, it is here to show _how_ to do it, not how to do
it _fast_.  Because  it's  a  'complex'  transform,  it  has to do a
'complex' multiply, and that means it takes twice as  many  ModMul's
as  a  NTT does.  Which means a pi program would take twice as long!
Which is why its here and not being wored on.


Nussbaumer
**********

I also investigated the Nussbaumer convolution, which  is  tied  for
being  theoretically best.  However, 'theoretically' does not equate
to  'real'  in  the  real  world.   I  never  reached  the  point of
implementing it in the pi program (just a tester for the mul itself)
but unfortunately, the original example code that I played with  was
GPL,  and  therefor  I  can't include it.  It's an interesting idea,
though.  It uses a  'fake'  FFT  to  process  the data.  But it just
doesn't have the performance.  I spent months on it and the op count
was too high and the disk I/O count would have been even higher.


